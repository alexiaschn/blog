<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.42">

  <meta name="author" content="Alexia Schneider">
  <meta name="dcterms.date" content="2025-11-03">
  <title>Alexia Schneider – Evaluating RAG with RAGAS</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-2f366650f320edcfcf53d73c80250a32.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Evaluating RAG with RAGAS</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Alexia Schneider 
</div>
<div class="quarto-title-author-email">
<a href="mailto:alexia.schneider@umontreal.ca">alexia.schneider@umontreal.ca</a>
</div>
</div>
</div>

  <p class="date">2025-11-03</p>
</section><section id="TOC">
<nav role="doc-toc"> 
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#/some-limitations-of-llms" id="/toc-some-limitations-of-llms">Some limitations of LLMs</a></li>
<li><a href="#/rag" id="/toc-rag">RAG</a></li>
<li><a href="#/the-original-rag-paper" id="/toc-the-original-rag-paper">The original RAG paper</a></li>
<li><a href="#/what-limitations-of-foundational-llms-can-rag-solve" id="/toc-what-limitations-of-foundational-llms-can-rag-solve">What limitations of foundational LLMs can RAG solve ?</a>
<ul>
<li><a href="#/what-limitations-of-foundational-llms-can-rag-solve-1" id="/toc-what-limitations-of-foundational-llms-can-rag-solve-1">What limitations of foundational LLMs can RAG solve ?</a></li>
</ul></li>
<li><a href="#/what-can-be-some-limits-of-rag" id="/toc-what-can-be-some-limits-of-rag">What can be some limits of RAG ?</a>
<ul>
<li><a href="#/what-can-be-some-limits-of-rag-1" id="/toc-what-can-be-some-limits-of-rag-1">What can be some limits of RAG ?</a></li>
<li><a href="#/evaluating-rag-when-and-where" id="/toc-evaluating-rag-when-and-where">Evaluating RAG: when and where</a></li>
<li><a href="#/shankarapplicationcentricaievals2025-recommendations-for-rag-evaluation" id="/toc-shankarapplicationcentricaievals2025-recommendations-for-rag-evaluation"><span class="citation" data-cites="shankarApplicationCentricAIEvals2025">Shankar and Husain (2025)</span> recommendations for RAG Evaluation</a></li>
<li><a href="#/reference-based-evaluation-pros-and-cons" id="/toc-reference-based-evaluation-pros-and-cons">Reference-based evaluation pros and cons</a></li>
</ul></li>
<li><a href="#/what-are-some-tasks-where-a-reference-answer-or-gold-standard-answer-might-not-be-available" id="/toc-what-are-some-tasks-where-a-reference-answer-or-gold-standard-answer-might-not-be-available">What are some tasks where a reference answer or ‘gold-standard answer’ might not be available ?</a>
<ul>
<li><a href="#/what-are-some-tasks-where-a-reference-answer-might-not-be-available" id="/toc-what-are-some-tasks-where-a-reference-answer-might-not-be-available">What are some tasks where a reference answer might not be available ?</a></li>
</ul></li>
<li><a href="#/proposed-solution-ragas" id="/toc-proposed-solution-ragas">Proposed solution: RAGAS</a>
<ul>
<li><a href="#/article" id="/toc-article">Article</a></li>
<li><a href="#/authors" id="/toc-authors">Authors</a></li>
<li><a href="#/ragas-in-a-nutshell" id="/toc-ragas-in-a-nutshell">RAGAS in a nutshell</a></li>
<li><a href="#/ragas-in-a-nutshell-1" id="/toc-ragas-in-a-nutshell-1">RAGAS in a nutshell</a></li>
<li><a href="#/evaluation-of-the-final-output" id="/toc-evaluation-of-the-final-output">Evaluation of the final output</a></li>
<li><a href="#/faithfulness-eval-with-ragas" id="/toc-faithfulness-eval-with-ragas">Faithfulness eval with RAGAS</a></li>
<li><a href="#/answer-relevance" id="/toc-answer-relevance">Answer Relevance</a></li>
<li><a href="#/context-relevance" id="/toc-context-relevance">Context Relevance</a></li>
</ul></li>
<li><a href="#/evaluation-of-the-evaluation-method" id="/toc-evaluation-of-the-evaluation-method">Evaluation of the evaluation method</a>
<ul>
<li><a href="#/evaluation-dataset" id="/toc-evaluation-dataset">Evaluation Dataset</a></li>
<li><a href="#/evaluation-of-the-evaluation-method-1" id="/toc-evaluation-of-the-evaluation-method-1">Evaluation of the evaluation method</a></li>
<li><a href="#/evaluation-results" id="/toc-evaluation-results">Evaluation results</a></li>
<li><a href="#/other-methods-of-rag-evaluation" id="/toc-other-methods-of-rag-evaluation">Other methods of RAG evaluation</a></li>
<li><a href="#/difference-between-automated-rag-evaluation-system-ares-framework-and-ragas" id="/toc-difference-between-automated-rag-evaluation-system-ares-framework-and-ragas">Difference between <em>Automated RAG Evaluation System</em> ARES framework and RAGAS</a></li>
<li><a href="#/would-you-use-ragas-to-evaluate-your-rag" id="/toc-would-you-use-ragas-to-evaluate-your-rag">Would you use RAGAS to evaluate your RAG?</a></li>
<li><a href="#/personal-comments-on-ragas" id="/toc-personal-comments-on-ragas">Personal comments on RAGAS</a></li>
<li><a href="#/references" id="/toc-references">References</a></li>
</ul></li>
</ul>
</nav>
</section>
<section id="some-limitations-of-llms" class="slide level2 hidden">
<h2>Some limitations of LLMs</h2>
<p>General limitations:</p>
<ul>
<li>explainability and transparency of output : black-box effect.</li>
<li>stochastic : not reliable answers</li>
<li>deciphering the user intention (the query)</li>
<li>training on specific task requires a lot of annotated data</li>
</ul>
<p>Specific problems:</p>
<ul>
<li>memory problem : implicit knowledge base that cannot easily be expanded or revised,</li>
<li>limited context window (if some companies boast 120k-input-token-window models, their performance still lags beyond 30k tokens <span class="citation" data-cites="shankarApplicationCentricAIEvals2025">(<a href="#/references" role="doc-biblioref" onclick="">Shankar and Husain 2025</a>)</span>).</li>
</ul>
</section>
<section id="rag" class="slide level2">
<h2>RAG</h2>
<p>Key point: Retrieval Augmentated Generation is an architecture for AI-integrated systems. It relies on an external knowledge base to improve on the overall quality of a generative LLM’s output.</p>
<blockquote>
<p>a foundational architecture in modern LLM systems” —<span class="citation" data-cites="shankarApplicationCentricAIEvals2025">(<a href="#/references" role="doc-biblioref" onclick="">Shankar and Husain 2025</a>)</span></p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="img/RAGWeaviate.png"></p>
<figcaption>Description of the RAG architecture from <span class="citation" data-cites="weaviateAdvancedRAGTechniques2025">Weaviate (<a href="#/references" role="doc-biblioref" onclick="">2025</a>)</span></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="img/rag.png"></p>
<figcaption>Basic schema of a RAG system, an architecture or pipeline for LLM-integrated systems</figcaption>
</figure>
</div>
</section>
<section id="the-original-rag-paper" class="slide level2 hidden">
<h2>The original RAG paper</h2>
<p>Original paper by <span class="citation" data-cites="lewisRetrievalAugmentedGenerationKnowledgeIntensive2021">Lewis et al. (<a href="#/references" role="doc-biblioref" onclick="">2021</a>)</span></p>
<p>Authors from:</p>
<ul>
<li>Facebook AI Research</li>
<li>University College London</li>
<li>New York University</li>
</ul>
<p>NB: Before the launch of ChatGPT (GPT-3.5 in nov. 2022). They use BART and GPT-2.</p>
<p>Key elements :</p>
<ul>
<li>parametric memory = the model: pre-trained <code>seq2seq</code> (early Transformers architecture).</li>
<li>non-parametric memory = external knowledge base: dense vector index of Wikipedia</li>
<li>IR strategy = encoder-decoder: pre-trained neural retriever. No supervision of the document that should be retrieved.</li>
</ul>
<div style="font-size: 50%;">
<p>Comments:</p>
<ul>
<li>Retrieval ablation shows that although a learned retrieval improves results on all tasks, the fack-checking (against Wikipedia) dataset FEVER performs best with a BM25 (improved TF-iDF).</li>
</ul>
</div>
</section>
<section>
<section id="what-limitations-of-foundational-llms-can-rag-solve" class="title-slide slide level1 center">
<h1>What limitations of foundational LLMs can RAG solve ?</h1>

</section>
<section id="what-limitations-of-foundational-llms-can-rag-solve-1" class="slide level2">
<h2>What limitations of foundational LLMs can RAG solve ?</h2>
<ul>
<li><strong>Reliability and transparency (for the dev)</strong>: providing a specialized and human verified external knowledge source ensures that the model will output based on those elements rather than it’s implicit knowledge base.</li>
<li><strong>Better reproducibility</strong>: traceable sources and choice of IR strategy.</li>
<li><strong>Preservation of the general-purpose and adaptability of foundational LLMs</strong>: doesn’t require special training or fine-tuning on a specific task.</li>
</ul>
</section></section>
<section>
<section id="what-can-be-some-limits-of-rag" class="title-slide slide level1 center">
<h1>What can be some limits of RAG ?</h1>

</section>
<section id="what-can-be-some-limits-of-rag-1" class="slide level2">
<h2>What can be some limits of RAG ?</h2>
<p>Higher level problems:</p>
<ul>
<li><strong>Dataset biais</strong>: External knowledge base = dataset with its bias and limitations too.</li>
<li><strong>Cost</strong>: Adding to regular prompt engineering: encoding the external knowledge base, DBB storage, eval and maintenance of a complex system, longer prompts containing extra info.</li>
<li><strong>Latency</strong>: pipeline = increased response time.</li>
<li><strong>Complexity</strong>: Many parameters = complex evaluation and optimization: IR strategy (TF-iDF/BM25 or semantic search with vector proximity, neural retrievers), chunk size, number of chunks provided and ranking algorithm (top-k).</li>
</ul>
<p>Internal problems:</p>
<ul>
<li><strong>Information dissemination</strong>: what if the chunks needed end up being too big or numerous for the LLM to be competent?</li>
<li><strong>‘Blind spot’ effect</strong>: if the key information is in a chunk not retrieved, then that part is lost to the user.</li>
</ul>
<div>
<ul>
<li class="fragment"><div style="font-size: 200%;">
<strong>Evaluation : each step of the pipeline can cause failures</strong>
</div></li>
</ul>
</div>
</section>
<section id="evaluating-rag-when-and-where" class="slide level2">
<h2>Evaluating RAG: when and where</h2>
<div class="figure">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="img/eval_rag.png"></p>
<figcaption>Checkpoints for evaluation: A. Chunk size and type. B. Retrieval strategy. C. Reranker algorithm. D. Final output considering the entire flow.</figcaption>
</figure>
</div>
</div>
</section>
<section id="shankarapplicationcentricaievals2025-recommendations-for-rag-evaluation" class="slide level2">
<h2><span class="citation" data-cites="shankarApplicationCentricAIEvals2025">Shankar and Husain (<a href="#/references" role="doc-biblioref" onclick="">2025</a>)</span> recommendations for RAG Evaluation</h2>
<p>General recommendations for evaluation:</p>
<ul>
<li>Identify where the pipeline weakens (or where it breaks)</li>
<li>Evaluate at each step</li>
<li><strong>Form an evaluation dataset of expected queries, retrieved context and gold-standard answers</strong></li>
</ul>
<!-- 
<div style="font-size: 50%;">
Specific recommendations:

- chunking strategies (size, overlap, method (fixed window, sentence, advanced semantic segmentation))
    - perform a grid search on every combination possible 
    - leverage the document structure and metadata (augment each chunk with section heading and doc title for example) 
</div> 

Metrics for each step:

- Retrieval metrics: Recall@k and NDCG@k. 
- Reranking metrics: MRR or NDCG
- Final output: faithfulness and relevance metrics (ARES framework [@saad-falcon-etal-2024-ares])

Reminder: 

- Recall = did we catch all relevant document
- Precision = were all the document retrieved relevant. 
- MRR : Mean Reciprocal Rank: measures how early the first relevant doc appears in the ranking. Score 1/top-k if doc is in top-k otherwise 0. 
- NDCG@k : Normalized Discounted Cumulative Gain: grading relevance for ranking. Rewards placing more relevant items higher. Essentially, compares docs to each other to figure out which is more relevant. -> might produce counterintuitive scores ex: if all docs are irrelevant but ranked in the right order would give a high score. OR would  give a lower score if the best possible doc is retrieved but ranked lower even though that only doc is essential. 
-->
</section>
<section id="reference-based-evaluation-pros-and-cons" class="slide level2">
<h2>Reference-based evaluation pros and cons</h2>
<table class="caption-top">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>pros</th>
<th>cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>control of output from expected user behaviour</td>
<td>user query might not fit expected queries ( e.g.&nbsp;edge cases and jailbreak attempts)</td>
</tr>
<tr class="even">
<td>fixed dataset means that different prompting strategies can be assessed over time</td>
<td>annotation is time consuming</td>
</tr>
</tbody>
</table>
</section></section>
<section>
<section id="what-are-some-tasks-where-a-reference-answer-or-gold-standard-answer-might-not-be-available" class="title-slide slide level1 center">
<h1>What are some tasks where a reference answer or ‘gold-standard answer’ might not be available ?</h1>

</section>
<section id="what-are-some-tasks-where-a-reference-answer-might-not-be-available" class="slide level2">
<h2>What are some tasks where a reference answer might not be available ?</h2>
<ul>
<li>Open-ended queries</li>
<li>Summarization</li>
<li>Interpretative tasks</li>
<li>Changing context</li>
</ul>
</section></section>
<section>
<section id="proposed-solution-ragas" class="title-slide slide level1 center">
<h1>Proposed solution: RAGAS</h1>

</section>
<section id="article" class="slide level2">
<h2>Article</h2>
<div class="figure">
<p><img data-src="img/ragas_paper.png"></p>
<p>Submitted on <strong>26 Sep 2023 (v1)</strong>, last revised 28 Apr 2025 (this version, v2) on <a href="https://arxiv.org/abs/2309.15217">arXiv</a>.</p>
</div>
</section>
<section id="authors" class="slide level2">
<h2>Authors</h2>
<div class="figure">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="img/ragas_paper.png"></p>
<figcaption><span class="citation" data-cites="esRagasAutomatedEvaluation2025">Es et al. (<a href="#/references" role="doc-biblioref" onclick="">2025</a>)</span></figcaption>
</figure>
</div>
</div>
<ul>
<li>Exploding Gradients : private company that built RAGAS (open-source oriented)</li>
<li>CardiffNLP : Schockaert: worked on EvoPrompt.</li>
<li><a href="https://amplyfi.com/">AMPLYFI</a>: private company for market insights</li>
</ul>
</section>
<section id="ragas-in-a-nutshell" class="slide level2">
<h2>RAGAS in a nutshell</h2>
<p>Key element: <strong>Reference-free (not tied to having ground truth available) evaluation framework for retrieval agumented generation</strong></p>
<p>Essentially: a series of prompts to decompose the evaluation for specific aspects of the RAG (faithfulness, answer relevance, context relevance).</p>
<p>Integration: <code>llama-index</code> and <code>Langchain</code>.</p>
<p>Available: <a href="https://github.com/explodinggradients/ragas">https://github.com/explodinggradients/ragas</a></p>
<p>Ratings: 11.1k stars on GitHub</p>
</section>
<section id="ragas-in-a-nutshell-1" class="slide level2">
<h2>RAGAS in a nutshell</h2>

<img data-src="img/eval_rag.png" class="r-stretch quarto-figure-center"><p class="caption">RAGAS suggests an evaluation at the final step (D)</p></section>
<section id="evaluation-of-the-final-output" class="slide level2">
<h2>Evaluation of the final output</h2>
<ul>
<li>Faithfulness: <strong>The answer should be grounded in provided context.</strong>
<ul>
<li>hallucinations</li>
<li>omissions</li>
<li>misinterpretation</li>
</ul></li>
</ul>
<p>Answer Relevance: <strong>The generated answer should address the actual question.</strong></p>
<p>Context Relevance: <strong>Retrieved context should be focused, containing as little irrelevant information as possible.</strong></p>
</section>
<section id="faithfulness-eval-with-ragas" class="slide level2 scrollable">
<h2>Faithfulness eval with RAGAS</h2>
<p><strong>The answer should be grounded in provided context</strong></p>
<div style="color: green;">
<p><strong>Example: You have designed a RAG system to help you with your courses notes. You want to make sure that the IA-system answers based on the content of the course as it is very advanced knowledge and not from unreliable sources (the web).</strong></p>
</div>
<p>Strategy:</p>
<ol type="1">
<li>Create statements from the output given a user query.</li>
</ol>
<p>Prompt:</p>
<blockquote>
<p><code>Given a question and answer, create one or more statements from each sentence in the given  answer. \n question: [question] answer: [answer]</code></p>
</blockquote>
<div style="color: green;">
<p>Question = query = <strong>“Can you summarize last week’s course?”</strong></p>
<p>Answer = output =</p>
<p><strong>“Here’s a concise summary of your Week 8 – AI Agent Architecture course content:</strong></p>
<ul>
<li><p><strong>Agents are autonomous systems that:</strong></p>
<ul>
<li><strong>Interact not only with users but also with each other and their environment.</strong></li>
<li><strong>Go beyond simple LLM + tool use (sometimes called a “single agent”).”</strong></li>
</ul></li>
</ul>
<p>Statements created for evaluation =</p>
<ol type="1">
<li><p><strong>“The course discussed in Week 8 is titled”AI Agent Architecture.”</strong></p></li>
<li><p><strong>“The week focused on the structure, interaction, and evolution of AI agents.”</strong></p></li>
<li><p><strong>“Agents are autonomous systems.”</strong></p></li>
<li><p><strong>“Agents interact with users, other agents, and their environment.”</strong></p></li>
</ol>
</div>
<ol start="2" type="1">
<li>LLM-as-judge to evaluate the statement against the retrieved context.</li>
</ol>
<p>Prompt:</p>
<blockquote>
<p><code>Consider the given context and following statements, then determine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ...  statement: [statement n]</code></p>
</blockquote>
<div style="color: green;">
<p>Context: <strong>course.md week1, week8, week <em>n</em>, syllabus.xslx chunk 1, chunk <em>n</em>.</strong></p>
<p>Statement to assess : <strong>“The course discussed in Week 8 is titled”AI Agent Architecture.”</strong></p>
<p>Evaluation output : <strong>“Chunk 1 of the Syllabus provided does mention that the topic of Week 8 is AI Agent Architecture. Verdict : Yes”</strong></p>
</div>
<p><strong>Metric : supported statements/total number of statements</strong></p>
</section>
<section id="answer-relevance" class="slide level2">
<h2>Answer Relevance</h2>
<p><strong>The generated answer should address the actual question.</strong></p>
<p>Strategy: Retro-engineering what the question could have been from the answer.</p>
<p><code>Generate a question for the given answer. answer: [answer]</code></p>
<div style="color: green;">
<p>From the output summary:</p>
<p>Possible Question: <strong>“What are the key concepts, models, and research papers covered in <em>Week 8 – AI Agent Architecture</em>, and how do they illustrate the evolution from single LLM-based systems to multi-agent ecosystems?”</strong></p>
<p><strong>To be compared with the actual query: “Can you summarize last week’s course?”</strong></p>
</div>
<p><strong>Metric : Cosine similarity between the actual question and the generated answer.</strong></p>
</section>
<section id="context-relevance" class="slide level2">
<h2>Context Relevance</h2>
<p><strong>Retrieved context should be focused, containing as little irrelevant information as possible.</strong> <!-- 
This is important given the cost associated with feeding long context passages to LLMs. 

Replaces the ranking analysis suggested by Shankar.   --></p>
<p>Strategy: Extracting sentences from the context that have could have been used to give the answer.</p>
<p>Prompt:</p>
<blockquote>
<p><code>Please extract relevant sentences from the provided context that can potentially help answer the following question. If no relevant sentences are found, or if you believe the question cannot be answered from the given context, return the phrase "Insufficient Information". While extracting candidate sentences you’re not allowed to make any changes to sentences from given context.</code></p>
</blockquote>
<p>Helps analyse the granularity of the chunks provided and noise in the top-k (tells you whether there is anything relevant or not in the context).</p>
<p><strong>Metric : number of extracted sentences/total number of sentences</strong></p>
</section></section>
<section>
<section id="evaluation-of-the-evaluation-method" class="title-slide slide level1 center">
<h1>Evaluation of the evaluation method</h1>

</section>
<section id="evaluation-dataset" class="slide level2 scrollable">
<h2>Evaluation Dataset</h2>
<p><strong><a href="https://huggingface.co/datasets/explodinggradients/WikiEval">WikiEval Dataset</a> : created for the purpose of RAGAS.</strong></p>
<p>Question/Answers created from 50 wiki pages (after 2022 to avoid reliance on implicit knowledge).</p>
<ol type="1">
<li>Creation of the Question</li>
</ol>
<p>Prompt:</p>
<blockquote>
<p><code>Your task is to formulate a question from given context satisfying the rules given below: 1. The question should be fully answered from the given context. 2. The question should be framed from a part that contains non-trivial information. 3. The answer should not contain any links. 4. The question should be of moderate difficulty. 5. The question must be reasonable and must be understood and responded to by humans. 6. Do not use phrases that ’provided context’, etc in the question context:</code></p>
</blockquote>
<ol start="2" type="1">
<li>Generation of the Answer</li>
</ol>
<p>Prompt:</p>
<blockquote>
<p><code>Answer the question using the information from the given context. question: [question] context: [context]</code></p>
</blockquote>
<ol start="3" type="1">
<li>Annotation by 2 humans with interannotation agreement reaching 95% (faithfulness and context relevance) and 90% (answer relevance).</li>
</ol>
</section>
<section id="evaluation-of-the-evaluation-method-1" class="slide level2">
<h2>Evaluation of the evaluation method</h2>
<p>Their evaluation relies on the agreement of the method with a human annotator based on pairwise comparisons != absolute scores.</p>
<table class="caption-top">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>question</th>
<th>answer A</th>
<th>answer B</th>
<th>context</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>When is the <strong>scheduled launch date and time</strong> for the PSLV-C56 mission, and where will it be launched from?</td>
<td>The PSLV-C56 mission is scheduled to be launched on <strong>Sunday, 30 July 2023 at 06:30 IST / 01:00 UTC.</strong> It will be launched from the Satish Dhawan Space Centre, Sriharikota, Andhra Pradesh, India.</td>
<td><strong>The scheduled launch date and time for the PSLV-C56 mission have not been provided.</strong>The PSLV-C56 mission is an important space mission for India. It aims to launch a satellite into orbit to study weather patterns.’</td>
<td>“The PSLV-C56 is the 58th mission of Indian Space Research Organisation’s Polar Satellite Launch Vehicle (PSLV) and the 17th flight of the PSLV-CA variant, and will be get launched from Satish Dhawan Space Centre First Launch Pad ( FLP ).is Scheduled to get launched on Sunday, <strong>30 July 2023 at 06:30 IST / 01:00 UTC</strong> from Satish Dhawan Space Centre, Sriharikota, Andhra Pradesh, India. This is a dedicated commercial mission through NSIL with DS-SAR as primary satellite and VELOX-AM as a co-passenger satellite With other 5 Satellites, All satellites from this mission belongs to Singapore.”</td>
</tr>
</tbody>
</table>
<p>Ragas is compared to :</p>
<ul>
<li>GPT Score : for faithfulnes, range 0-10.</li>
</ul>
<p>GPT Score Prompt:</p>
<blockquote>
<p><code>Faithfulness measures the information consistency of the answer against the given context. Any claims that are made in the answer that cannot be deduced from context should be penalized. Given an answer and context, assign a score for faithfulness in the range 0-10. context: [context] answer: [answer]</code></p>
</blockquote>
<ul>
<li>GPT Ranking: for answer relevancy, ranking.</li>
</ul>
<p>GPT Ranking Prompt:</p>
<blockquote>
<p><code>Answer Relevancy measures the degree to which a response directly addresses and is appropriate for a given question. It penalizes the present of redundant information or incomplete answers given a question. Given an question and answer, rank each answer based on Answer Relevancy.  question: [question] answer 1: [answer 1] answer 2: [answer 2]</code></p>
</blockquote>
</section>
<section id="evaluation-results" class="slide level2">
<h2>Evaluation results</h2>
<div class="figure">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="img/tbl-evalRAGAS.png"></p>
<figcaption>Evaluation of 3 evaluation methods on the WikiEval dataset</figcaption>
</figure>
</div>
</div>
<blockquote>
<p>« The results in Table 1 show that our proposed metrics are <strong>much closer aligned with the human judgements than the predictions from the two baselines</strong>.</p>
</blockquote>
<blockquote>
<p>For faithfulness, the Ragas prediction are in general highly accurate.</p>
</blockquote>
<blockquote>
<p>For answer relevance, the agreement is lower, but this is largely due to the fact that the differences between the two candidate answers are often very subtle.</p>
</blockquote>
<blockquote>
<p>We found context relevance to be the hardest quality dimension to evaluate. In particular, we observed that ChatGPT often struggles with the task of selecting the sentences from the context that are crucial, especially for longer contexts. » (<a href="zotero://select/library/items/FJATA7IM">Es et al., 2025, p.&nbsp;5</a>) (<a href="zotero://open-pdf/library/items/3LHXZQXW?page=5&amp;annotation=JY45VWXF">pdf</a>)</p>
</blockquote>
</section>
<section id="other-methods-of-rag-evaluation" class="slide level2">
<h2>Other methods of RAG evaluation</h2>
<p>Reference-based score:</p>
<ul>
<li>BERTScore</li>
<li>MoverScore</li>
</ul>
<p>-&gt; Comparison between vector of output and “golden standard” answer.</p>
<p>Reference-less score:</p>
<ul>
<li>Asking ChatGPT to score the output (scale of 0 to 100) -&gt; GPT Score and GPT Ranking</li>
<li>ARES</li>
</ul>
</section>
<section id="difference-between-automated-rag-evaluation-system-ares-framework-and-ragas" class="slide level2">
<h2>Difference between <em>Automated RAG Evaluation System</em> ARES framework and RAGAS</h2>
<p><span class="citation" data-cites="saad-falcon-etal-2024-ares">Saad-Falcon et al. (<a href="#/references" role="doc-biblioref" onclick="">2024</a>)</span> (a year after RAGAS).</p>
<p>Synthetic data generation (generating query‑passage‑answer triples) + fine‑tuned “judge” models + a small human annotated set + Prediction‑Powered Inference (PPI) to give confidence intervals, better ranking of RAG systems.</p>
<p>Comment: much more complex to set-up, but better for robust eval (confidence intervals)</p>
</section>
<section id="would-you-use-ragas-to-evaluate-your-rag" class="slide level2">
<h2>Would you use RAGAS to evaluate your RAG?</h2>
</section>
<section id="personal-comments-on-ragas" class="slide level2">
<h2>Personal comments on RAGAS</h2>
<p>Strengths:</p>
<ul>
<li>Reproducibility: they provide the prompts in full</li>
<li>Clever workaround for the context relevance (with cosine similarity between query and retroengineered query).</li>
<li>Easy and intuitive implementation.</li>
</ul>
<p>Limits:</p>
<p>Evaluation of the evaluation method:</p>
<ul>
<li>The model used to create the dataset and to perform the ragas seems to be the same (namely ChatGPT without stating its version) : bias towards better performances at it would agree with itself more and create answer and questions that resemble more the kind of ‘statements’ it would generate.</li>
<li>Compared evaluation methods, GPT Score and GPT Ranking are not strong LLM-as-judge methods.</li>
<li>Limited dataset of 50 Q&amp;A.</li>
</ul>
<p>RAGAS as evaluation: - Splitting the answer into statements (faithfulness score) adds another layer of interpretation by the LLM, increasing chances of hallucinations etc. - Lack of certainty assessment.</p>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-esRagasAutomatedEvaluation2025" class="csl-entry" role="listitem">
Es, Shahul, Jithin James, Luis Espinosa-Anke, and Steven Schockaert. 2025. <span>“Ragas: <span>Automated Evaluation</span> of <span>Retrieval Augmented Generation</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2309.15217">https://doi.org/10.48550/arXiv.2309.15217</a>.
</div>
<div id="ref-lewisRetrievalAugmentedGenerationKnowledgeIntensive2021" class="csl-entry" role="listitem">
Lewis, Patrick, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, et al. 2021. <span>“Retrieval-<span>Augmented Generation</span> for <span>Knowledge-Intensive NLP Tasks</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2005.11401">https://doi.org/10.48550/arXiv.2005.11401</a>.
</div>
<div id="ref-saad-falcon-etal-2024-ares" class="csl-entry" role="listitem">
Saad-Falcon, Jon, Omar Khattab, Christopher Potts, and Matei Zaharia. 2024. <span>“<span>ARES</span>: <span>An</span> Automated Evaluation Framework for Retrieval-Augmented Generation Systems.”</span> In <em>Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: <span>Human</span> Language Technologies (Volume 1: <span>Long</span> Papers)</em>, edited by Kevin Duh, Helena Gomez, and Steven Bethard, 338–54. Mexico City, Mexico: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2024.naacl-long.20">https://doi.org/10.18653/v1/2024.naacl-long.20</a>.
</div>
<div id="ref-shankarApplicationCentricAIEvals2025" class="csl-entry" role="listitem">
Shankar, Shreya, and Hamel Husain. 2025. <em>Application-<span>Centric AI Evals</span> for <span>Engineers</span> and <span>Technical Product Managers</span></em>.
</div>
<div id="ref-weaviateAdvancedRAGTechniques2025" class="csl-entry" role="listitem">
Weaviate. 2025. <span>“Advanced <span>RAG Techniques</span>.”</span> <em>Weaviate Ebook</em>.
</div>
</div>
</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>